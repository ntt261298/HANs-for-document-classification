{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "[nltk_data] Downloading package stopwords to /Users/gotit/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/gotit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import time\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score, accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_time(t1, t2):\n",
    "    diff = t2 - t1\n",
    "    mins = int(diff / 60)\n",
    "    secs = round(diff % 60, 3)\n",
    "    return str(mins) + \" mins and \" + str(secs) + \" seconds\"\n",
    "\n",
    "def clean_str(sentence):\n",
    "    # Remove HTML\n",
    "    review_text = BeautifulSoup(sentence, features=\"html.parser\").text\n",
    "    # Remove non-letters\n",
    "    letters_only = re.sub(\"[^a-zA-Z\\s\\s+]\", \"\", review_text).strip()\n",
    "    return letters_only\n",
    "\n",
    "def convert_plain_to_csv(text_file, csv_file):\n",
    "    t0 = time.time()\n",
    "    with open(text_file, \"r\") as f1, open(csv_file, \"w\") as f2:\n",
    "        i = 0\n",
    "        f2.write(\"productId,score,summary,text\\n\")\n",
    "        while True:\n",
    "            next_n_lines = list(islice(f1, 9))  # read 9 line\n",
    "            if not next_n_lines:\n",
    "                break\n",
    "\n",
    "            output_line = \"\"\n",
    "            for line in next_n_lines:\n",
    "                if \"product/productId:\" in line:\n",
    "                    output_line += line.split(\":\")[1].strip() + \",\"\n",
    "                elif \"review/score:\" in line:\n",
    "                    output_line += line.split(\":\")[1].strip() + \",\"\n",
    "                elif \"review/summary:\" in line:\n",
    "                    summary = clean_str(line.split(\":\")[1].strip()) + \",\"\n",
    "                    output_line += summary\n",
    "                elif \"review/text:\" in line:\n",
    "                    text = clean_str(line.split(\":\")[1].strip()) + \"\\n\"\n",
    "                    output_line += text\n",
    "\n",
    "            f2.write(output_line)\n",
    "\n",
    "            # print status\n",
    "            i += 1\n",
    "            if i % 10000 == 0:\n",
    "                print(i, \"reviews converted...\")\n",
    "\n",
    "    print(datetime.datetime.now(), \"- Converting completed in\", get_run_time(t0, time.time()))\n",
    "\n",
    "def get_data(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"-- \" + file_name + \" found locally\")\n",
    "        df = pd.read_csv(file_name)\n",
    "    return df\n",
    "\n",
    "def review_to_words(review):\n",
    "    # 1. Convert to lower case, split into individual words\n",
    "    words = review.lower().split()\n",
    "\n",
    "    # 2. Get english stop words\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # 3. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]\n",
    "    \n",
    "    return \" \".join(meaningful_words)\n",
    "\n",
    "\n",
    "def cleaning_data(dataset, file_name):\n",
    "    t0 = time.time()\n",
    "    num_reviews = dataset[\"text\"].size\n",
    "    clean_train_reviews = []\n",
    "\n",
    "    # Loop over each review\n",
    "    for i in range(0, num_reviews):\n",
    "        # If the index is evenly divisible by 1000, print a message\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            print(\"Review\", i + 1, \"of\", num_reviews, \"\\n\")\n",
    "\n",
    "        productId = str(dataset[\"productId\"][i])\n",
    "        score = str(dataset[\"score\"][i])\n",
    "        summary = str(dataset[\"summary\"][i])\n",
    "        text = review_to_words(str(dataset[\"text\"][i]))\n",
    "\n",
    "        clean_train_reviews.append(productId + \",\" + score + \",\" + summary + \",\" + text + \"\\n\")\n",
    "\n",
    "    print(\"Writing clean train reviews...\")\n",
    "    with open(file_name, \"w\") as f:\n",
    "        f.write(\"productId,score,summary,text\\n\")\n",
    "        for review in clean_train_reviews:\n",
    "            f.write(\"%s\\n\" % review)\n",
    "\n",
    "    \n",
    "    print(datetime.datetime.now(), \"- Write file completed in\", get_run_time(t0, time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 reviews converted...\n",
      "20000 reviews converted...\n",
      "30000 reviews converted...\n",
      "40000 reviews converted...\n",
      "50000 reviews converted...\n",
      "60000 reviews converted...\n",
      "70000 reviews converted...\n",
      "80000 reviews converted...\n",
      "90000 reviews converted...\n",
      "100000 reviews converted...\n",
      "110000 reviews converted...\n",
      "120000 reviews converted...\n",
      "130000 reviews converted...\n",
      "140000 reviews converted...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bs4/__init__.py:333: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150000 reviews converted...\n",
      "160000 reviews converted...\n",
      "170000 reviews converted...\n",
      "180000 reviews converted...\n",
      "190000 reviews converted...\n",
      "200000 reviews converted...\n",
      "210000 reviews converted...\n",
      "220000 reviews converted...\n",
      "230000 reviews converted...\n",
      "240000 reviews converted...\n",
      "250000 reviews converted...\n",
      "260000 reviews converted...\n",
      "270000 reviews converted...\n",
      "280000 reviews converted...\n",
      "290000 reviews converted...\n",
      "300000 reviews converted...\n",
      "310000 reviews converted...\n",
      "320000 reviews converted...\n",
      "330000 reviews converted...\n",
      "340000 reviews converted...\n",
      "350000 reviews converted...\n",
      "360000 reviews converted...\n",
      "370000 reviews converted...\n",
      "380000 reviews converted...\n",
      "390000 reviews converted...\n",
      "400000 reviews converted...\n",
      "410000 reviews converted...\n",
      "420000 reviews converted...\n",
      "430000 reviews converted...\n",
      "440000 reviews converted...\n",
      "450000 reviews converted...\n",
      "460000 reviews converted...\n",
      "470000 reviews converted...\n",
      "480000 reviews converted...\n",
      "490000 reviews converted...\n",
      "500000 reviews converted...\n",
      "510000 reviews converted...\n",
      "520000 reviews converted...\n",
      "530000 reviews converted...\n",
      "540000 reviews converted...\n",
      "550000 reviews converted...\n",
      "560000 reviews converted...\n",
      "2020-06-08 23:05:46.299255 - Converting completed in 2 mins and 25.285 seconds\n",
      "-- foods.csv found locally\n",
      "Data dimensions: (568454, 4)\n",
      "List features: ['productId' 'score' 'summary' 'text']\n",
      "Review 10000 of 568454 \n",
      "\n",
      "Review 20000 of 568454 \n",
      "\n",
      "Review 30000 of 568454 \n",
      "\n",
      "Review 40000 of 568454 \n",
      "\n",
      "Review 50000 of 568454 \n",
      "\n",
      "Review 60000 of 568454 \n",
      "\n",
      "Review 70000 of 568454 \n",
      "\n",
      "Review 80000 of 568454 \n",
      "\n",
      "Review 90000 of 568454 \n",
      "\n",
      "Review 100000 of 568454 \n",
      "\n",
      "Review 110000 of 568454 \n",
      "\n",
      "Review 120000 of 568454 \n",
      "\n",
      "Review 130000 of 568454 \n",
      "\n",
      "Review 140000 of 568454 \n",
      "\n",
      "Review 150000 of 568454 \n",
      "\n",
      "Review 160000 of 568454 \n",
      "\n",
      "Review 170000 of 568454 \n",
      "\n",
      "Review 180000 of 568454 \n",
      "\n",
      "Review 190000 of 568454 \n",
      "\n",
      "Review 200000 of 568454 \n",
      "\n",
      "Review 210000 of 568454 \n",
      "\n",
      "Review 220000 of 568454 \n",
      "\n",
      "Review 230000 of 568454 \n",
      "\n",
      "Review 240000 of 568454 \n",
      "\n",
      "Review 250000 of 568454 \n",
      "\n",
      "Review 260000 of 568454 \n",
      "\n",
      "Review 270000 of 568454 \n",
      "\n",
      "Review 280000 of 568454 \n",
      "\n",
      "Review 290000 of 568454 \n",
      "\n",
      "Review 300000 of 568454 \n",
      "\n",
      "Review 310000 of 568454 \n",
      "\n",
      "Review 320000 of 568454 \n",
      "\n",
      "Review 330000 of 568454 \n",
      "\n",
      "Review 340000 of 568454 \n",
      "\n",
      "Review 350000 of 568454 \n",
      "\n",
      "Review 360000 of 568454 \n",
      "\n",
      "Review 370000 of 568454 \n",
      "\n",
      "Review 380000 of 568454 \n",
      "\n",
      "Review 390000 of 568454 \n",
      "\n",
      "Review 400000 of 568454 \n",
      "\n",
      "Review 410000 of 568454 \n",
      "\n",
      "Review 420000 of 568454 \n",
      "\n",
      "Review 430000 of 568454 \n",
      "\n",
      "Review 440000 of 568454 \n",
      "\n",
      "Review 450000 of 568454 \n",
      "\n",
      "Review 460000 of 568454 \n",
      "\n",
      "Review 470000 of 568454 \n",
      "\n",
      "Review 480000 of 568454 \n",
      "\n",
      "Review 490000 of 568454 \n",
      "\n",
      "Review 500000 of 568454 \n",
      "\n",
      "Review 510000 of 568454 \n",
      "\n",
      "Review 520000 of 568454 \n",
      "\n",
      "Review 530000 of 568454 \n",
      "\n",
      "Review 540000 of 568454 \n",
      "\n",
      "Review 550000 of 568454 \n",
      "\n",
      "Review 560000 of 568454 \n",
      "\n",
      "Writing clean train reviews...\n",
      "2020-06-08 23:09:04.894538 - Write file completed in 3 mins and 15.988 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pre-processing\n",
    "\"\"\"\n",
    "convert_plain_to_csv(\"finefoods.txt\", \"foods.csv\")\n",
    "\n",
    "# Reading the Data\n",
    "train = get_data(\"foods.csv\")\n",
    "print(\"Data dimensions:\", train.shape)\n",
    "print(\"List features:\", train.columns.values)\n",
    "\n",
    "cleaning_data(train, \"clean_train_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from file\n",
    "reviews = pd.read_csv(\"clean_train_reviews.csv\", nrows=20000)\n",
    "# ignore all 3* reviews\n",
    "reviews = reviews[reviews[\"score\"] != 3]\n",
    "# positive sentiment = 4* or 5* reviews (sentriment = True)\n",
    "reviews[\"sentiment\"] = reviews[\"score\"] >= 4\n",
    "\n",
    "# X = reviews['text'].values.astype('U')\n",
    "X = reviews['text']\n",
    "y = reviews['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = MultinomialNB()\n",
    "svm_clf = svm.SVC(kernel='linear', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average accuracy across folds: 84.73%\n",
      "\n",
      "Average F1 score across folds: 90.58%\n",
      "\n",
      "Average Precision score across folds: 93.87%\n",
      "\n",
      "Average Recall score across folds: 87.52%\n",
      "\n",
      "Average Confusion Matrix across folds: \n",
      " [[ 413.9  176. ]\n",
      " [ 384.5 2696.6]]\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "pres = []\n",
    "recs = []\n",
    "vect = CountVectorizer(analyzer=\"word\",\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=1000)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index].values.astype('U'), X.iloc[test_index].values.astype('U')\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    Encoder = LabelEncoder() \n",
    "    y_train = Encoder.fit_transform (y_train) \n",
    "    y_test = Encoder.fit_transform (y_test)\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    naive.fit(X_train_res, y_train_res)\n",
    "    y_pred = naive.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    pres.append(precision_score(y_test, y_pred))\n",
    "    recs.append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(sum(pres) / len(pres) * 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(sum(recs) / len(recs) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average accuracy across folds: 83.76%\n",
      "\n",
      "Average F1 score across folds: 89.69%\n",
      "\n",
      "Average Precision score across folds: 96.00%\n",
      "\n",
      "Average Recall score across folds: 84.17%\n",
      "\n",
      "Average Confusion Matrix across folds: \n",
      " [[ 480.   108.1]\n",
      " [ 488.1 2594.8]]\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "pres = []\n",
    "recs = []\n",
    "vect = TfidfVectorizer(analyzer=\"word\",\n",
    "                                preprocessor=None,\n",
    "                                stop_words=None,\n",
    "                                max_features=1000)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index].values.astype('U'), X.iloc[test_index].values.astype('U')\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    Encoder = LabelEncoder() \n",
    "    y_train = Encoder.fit_transform (y_train) \n",
    "    y_test = Encoder.fit_transform (y_test)\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    naive.fit(X_train_res, y_train_res)\n",
    "    y_pred = naive.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    pres.append(precision_score(y_test, y_pred))\n",
    "    recs.append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(sum(pres) / len(pres) * 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(sum(recs) / len(recs) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average accuracy across folds: 85.57%\n",
      "\n",
      "Average F1 score across folds: 91.19%\n",
      "\n",
      "Average Precision score across folds: 93.44%\n",
      "\n",
      "Average Recall score across folds: 89.04%\n",
      "\n",
      "Average Confusion Matrix across folds: \n",
      " [[ 401.1  192.4]\n",
      " [ 337.3 2740.2]]\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "pres = []\n",
    "recs = []\n",
    "vect = CountVectorizer(analyzer=\"word\",\n",
    "                            preprocessor=None,\n",
    "                            stop_words=None,\n",
    "                            max_features=1000)\n",
    "                            \n",
    "for train_index, test_index in ss.split(X):\n",
    "\n",
    "    \n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index].values.astype('U'), X.iloc[test_index].values.astype('U')\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    svm_clf.fit(X_train_res, y_train_res)\n",
    "    y_pred = svm_clf.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    pres.append(precision_score(y_test, y_pred))\n",
    "    recs.append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(sum(pres) / len(pres) * 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(sum(recs) / len(recs) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average accuracy across folds: 86.04%\n",
      "\n",
      "Average F1 score across folds: 91.40%\n",
      "\n",
      "Average Precision score across folds: 94.60%\n",
      "\n",
      "Average Recall score across folds: 88.40%\n",
      "\n",
      "Average Confusion Matrix across folds: \n",
      " [[ 435.1  155.3]\n",
      " [ 357.2 2723.4]]\n"
     ]
    }
   ],
   "source": [
    "ss = ShuffleSplit(n_splits=10, test_size=0.2)\n",
    "sm = SMOTE()\n",
    "accs = []\n",
    "f1s = []\n",
    "cms = []\n",
    "pres = []\n",
    "recs = []\n",
    "vect = TfidfVectorizer(analyzer=\"word\",\n",
    "                                preprocessor=None,\n",
    "                                stop_words=None,\n",
    "                                max_features=1000)\n",
    "\n",
    "for train_index, test_index in ss.split(X):\n",
    "    \n",
    "    X_train, X_test = X.iloc[train_index].values.astype('U'), X.iloc[test_index].values.astype('U')\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    Encoder = LabelEncoder() \n",
    "    y_train = Encoder.fit_transform (y_train) \n",
    "    y_test = Encoder.fit_transform (y_test)\n",
    "    \n",
    "    # Fit vectorizer and transform X train, then transform X test\n",
    "    X_train_vect = vect.fit_transform(X_train)\n",
    "    X_test_vect = vect.transform(X_test)\n",
    "    \n",
    "    # Oversample\n",
    "    X_train_res, y_train_res = sm.fit_sample(X_train_vect, y_train)\n",
    "    \n",
    "    # Fit Naive Bayes on the vectorized X with y train labels, \n",
    "    # then predict new y labels using X test\n",
    "    svm_clf.fit(X_train_res, y_train_res)\n",
    "    y_pred = svm_clf.predict(X_test_vect)\n",
    "    \n",
    "    # Determine test set accuracy and f1 score on this fold using the true y labels and predicted y labels\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "    f1s.append(f1_score(y_test, y_pred))\n",
    "    cms.append(confusion_matrix(y_test, y_pred))\n",
    "    pres.append(precision_score(y_test, y_pred))\n",
    "    recs.append(recall_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAverage accuracy across folds: {:.2f}%\".format(sum(accs) / len(accs) * 100))\n",
    "print(\"\\nAverage F1 score across folds: {:.2f}%\".format(sum(f1s) / len(f1s) * 100))\n",
    "print(\"\\nAverage Precision score across folds: {:.2f}%\".format(sum(pres) / len(pres) * 100))\n",
    "print(\"\\nAverage Recall score across folds: {:.2f}%\".format(sum(recs) / len(recs) * 100))\n",
    "print(\"\\nAverage Confusion Matrix across folds: \\n {}\".format(sum(cms) / len(cms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
